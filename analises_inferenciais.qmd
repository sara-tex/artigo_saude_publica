---
title: "analises_inferenciais"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
library(ggrepel)
library(rstatix)
library(summarytools)
library(nortest)
library(MKinfer)
library(boot)
library(purrr)
```

```{r}
df <- read_csv("dados-limpo.csv") |> 
  filter(nivel_atencao %in% c("atenção primária", "atenção secundária", "atenção terciária"))
```

```{r}
df |> 
  count(genero) |> 
  mutate(
    prop = n / sum(n) * 100
  )
```


```{r}
```


```{r}
```


```{r}
```


```{r}
```

```{r}
# teste t para gênero
## considerar apenas um vínculo por psicólogo
vinculos_unicos <- df |> 
  filter(!is.na(genero)) |> 
  group_by(codigo_profissional_saude, genero) |> 
  summarise(
    n_vinculos = n(),
    .groups = 'drop'
  )

## testando pressupostos
### normalidade
norm_mulher <- vinculos_unicos |>
  filter(genero == "Female") |> 
  pull(n_vinculos) |> 
  lillie.test()

norm_homens <- vinculos_unicos |> 
  filter(genero == "Male") |> 
  pull(n_vinculos) |> 
  lillie.test()
### homogeneidade de variâncias
levene_test(vinculos_unicos, formula = n_vinculos ~ genero)
### bootstrap
boot_t_vinculos <- boot.t.test(formula = n_vinculos ~ genero, data = vinculos_unicos, 
                     R= 1000)
```


Usando o pacote genderBR, categorizou-se 59.286 vínculos como de mulheres ("Female"), 11.492 eram homens ("Male"), mas não foi possível categorizar 2.745 vínculos quanto ao gênero, sendo estes excluódos do banco de dados para proceder à análise da diferença de média por meio do teste t de Student.

Em razão do não atendimento ao pressuposto de normalidade, procedeu ao procedimento de bootstrap com 1000 reamostragens para verficar se há uma média de vinculos maior para homens ou mulheres. Constatou-se diferença estatisticamente significativa entre os grupos (t (13081) = -2,3965; p-value = 0.01657), no sentido de que há um número de médio maior para os homens do que para as mulheres. 



```{r}
# quantidade de psicólogos em cada região por nível de atenção
df |> 
  count(regiao, nivel_atencao) |> 
  pivot_wider(names_from = nivel_atencao, values_from = n, id_cols = regiao) 
```

```{r}
# tabela de contingência e teste de qui-quadrado da quantidade de vínculos em cada região por nível de atenção

ctable(x = df$regiao, y = df$nivel_atencao, chisq = T)
```

```{r}
#variável de proporção: "nº de habitantes por profissional de psicologia"
## agrupando por municipio para não contar municipio mais de uma vez 

df_prop <- df |>
  group_by(codigo_municipio, nome_do_municipio, regiao, estado) |> 
  summarise(
    populacao_muni = first(populacao_muni), 
    # n() agora contará corretamente centenas ou milhares de linhas para SP
    quanti_psis_muni = n(), 
    prop_psi_muni =  populacao_muni/quanti_psis_muni,
    .groups = 'drop'
  ) |>
  ungroup()

## fazer a análise por estado
```

```{r}

# verificando pressuposto da proporção 

df_prop |>
  group_by(regiao) |>
  shapiro_test(prop_psi_muni)

levene_test(prop_psi_muni ~ regiao, data = df_prop)

## aqui deu erro, porque a amostra é muito grande

df_prop |>
  group_by(estado) |>
  shapiro_test(prop_psi_muni)

levene_test(prop_psi_muni ~ estado, data = df_prop)
```

```{r}
#anova entre regiões (proporção por região)

modelo_regiao <- aov(prop_psi_muni ~ regiao, data = df_prop)

summary(modelo_regiao)

TukeyHSD(modelo_regiao) 

# testando pressuposto de normalidade de resíduos
lillie.test(residuals(modelo_regiao))

# testando homogeneidade de variâncias
levene_test(prop_psi_muni ~ regiao, data = df_prop)

# estatística descritiva
descritiva_anova <- df_prop |> 
  group_by(regiao) |> 
  get_summary_stats(
    prop_psi_muni,
    type = "full") |> 
  select(regiao, n, mean, sd)

# Anova de Welch (robusta à falta de homogeneidade de variância)
welch_anova <- oneway.test(prop_psi_muni ~ regiao, 
                           data = df_prop, 
                           var.equal = FALSE)

# tamanho de efeito global Eta Quadrado
efeito_global_anova <- eta_squared(modelo_regiao)

# Teste Post-Hoc de Games-Howell
post_hoc_anova <- df_prop |> 
  games_howell_test(prop_psi_muni ~ regiao) 

# tamanho de efeito das comparações 
efeito_regioes <- df_prop |> 
  cohens_d(prop_psi_muni ~ regiao,
           paired = F,
           hedges.correction = T) 

# Bootstrapping (robusto à falta de normalidade dos resíduos)
## pares de regiões
pares_regioes <- combn(unique(df_prop$regiao), 2, simplify = F)
## 2. Função para realizar o teste bootstrap e extrair o p-value
rodar_boot_test <- function(par) {
  grupo1 <- par[1]
  grupo2 <- par[2]
  
  dados_par <- df_prop |> 
    filter(regiao %in% c(grupo1, grupo2))
  
  test_boot <- boot.t.test(
    prop_psi_muni ~ regiao,
    data = dados_par,
    R = 2000,
    alternative = "two.sided"
  )
  
  data.frame(
    group1 = grupo1,
    group2 = grupo2,
    p.value = test_boot$p.value
  )
}
## 3. aplicar a função aos pares e mostrar os resultados com p-value
boot_anova <- do.call(rbind, lapply(pares_regioes, rodar_boot_test))

## 4. Aplicar a correção de Holm para mostrar valor de p
boot_anova_holm <- boot_anova |> 
  mutate(p.adj.holm = p.adjust(p.value, method = "holm"))
```

Não houve normalidade dos resíduos nem homogeneidade de variâncias. 

centro-oeste tem menos psicólos por população do que o sudeste proporcionalmente
nordeste tem mais psicólogos por população que o norte
nordeste tem menos psicólogos por pop do que o sudeste
nordeste tem menos psicólogos por pop do que o sul
norte tem menos psicólogos por pop do que o sudeste

norte tem menos psicólogos por pop do que o sul
e o sudeste tem menos psicólogos por população do que o sul

#verificar a prevalência de psicólogos por nível de atenção em cada região (ex.: nordeste tem mais psicólogos na atenção primária que sudeste?)

```{r}
#anova entre estados

modelo_estado <- aov(prop_psi_muni ~ estado, data = df_prop)

summary(modelo_estado)

TukeyHSD(modelo_estado)
  
```

Procedeu-se a uma análise de correlação no sentido de avaliar a relação entre a população do município e a proporção da quantidade de habitantes por psicólogo. Em razão do não atendimento do pressuposto de normalidade, foi realizada o teste de correlação de Spearman, cuja resultado indicou associação positiva e significativa (r(5484) = 0,33; p < 0,001), o que sugere que quanto mais pessoas residem no município, maior a demanda que os profissionais precisam atender. 

```{r}
#correlação entre população e nº de vínculos

## testando pressupostos
### normalidade 
#### populacao_muni
norm_pop_muni <- df_prop |> 
  pull(populacao_muni) |> 
  lillie.test()

norm_prop_psi_muni <- df_prop |> 
  pull(prop_psi_muni) |> 
  lillie.test()


## --> que função usar pra verificar os pressupostos?

cor.test(df_prop$populacao_muni, df_prop$prop_psi_muni, method = "spearman")

```

```{r}
library(ggplot2)

ggplot(df_prop, aes(x = populacao_muni, y = prop_psi_muni)) +
  geom_point(alpha = 0.6, color = "black") +
  geom_smooth(method = "lm", se = FALSE, color = "gray") + 
  geom_text_repel(
    data = df_prop |> slice_max(populacao_muni, n = 5),
    aes(label = nome_do_municipio), 
    size = 3, 
    box.padding = 0.5, 
    point.padding = 0.5,
    color = "black",
    max.overlaps = Inf) +labs(
    title = "Correlação entre População e Psicólogos",
    x = "População do Município",
    y = "Proporção de Psicólogos"
  ) +
  theme_minimal()
```


